{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import jieba\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\",delimiter=\"\\t\")\n",
    "test = pd.read_csv(\"test.csv\",delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwordslist():\n",
    "    stopwords = [line.strip() for line in open('cn_stopwords.txt',encoding='UTF-8').readlines()]\n",
    "    return stopwords\n",
    "\n",
    "def removepre(sentence):\n",
    "    pattern = re.compile(\"[^a-zA-Z0-9\\u4E00-\\u9FA5]\")\n",
    "    sentence = pattern.sub(\"\",sentence)\n",
    "    sentence = sentence.replace(\"#\",\"\")\n",
    "    sentence = sentence.replace(\"【\",\"\")\n",
    "    sentence = sentence.replace(\"】\",\"\")\n",
    "    return sentence\n",
    "\n",
    "\n",
    "def removenumber(sentence):\n",
    "    pattern = re.compile(\"[\\d+]\")\n",
    "    sentence = pattern.sub(\"\",sentence)\n",
    "    return sentence\n",
    "    \n",
    "        \n",
    "def seg_depart(sentence):\n",
    "     # 对文档中的每一行进行中文分词\n",
    "    sentence_depart = jieba.cut(sentence.strip())\n",
    "     # 创建一个停用词列表\n",
    "    stopwords = stopwordslist()\n",
    "    # 输出结果为outstr\n",
    "    outstr = ''\n",
    "   # 去停用词\n",
    "    for word in sentence_depart:\n",
    "        if word not in stopwords:\n",
    "            if word != '\\t':\n",
    "                outstr += word\n",
    "                outstr += \" \"\n",
    "    return outstr  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"cut\"] = train[\"text\"].apply(removepre)\n",
    "test[\"cut\"] = test[\"text\"].apply(removepre)\n",
    "\n",
    "train[\"cut\"] = train[\"cut\"].apply(removenumber)\n",
    "test[\"cut\"] = train[\"cut\"].apply(removenumber)\n",
    "\n",
    "train[\"cut\"] = train[\"cut\"].apply(seg_depart)\n",
    "test[\"cut\"] = train[\"cut\"].apply(seg_depart)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = [i for i in train[\"cut\"]]\n",
    "test_set = [i for i in test[\"cut\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = train_set+test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('dataset/training.csv',index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('dataset/testing.csv',index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>cut</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IphoneSE</td>\n",
       "      <td>讲真，对iphoneSE很心动，但是又很期待iphone7，心塞</td>\n",
       "      <td>刚   回家   几天   迫不及待   赶到   小舅   家   看着   乖巧   懂...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>春节放鞭炮</td>\n",
       "      <td>传统春节来临传统的拜神，放鞭炮，烧纸，热闹呢</td>\n",
       "      <td>俄罗斯   流氓</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>俄罗斯在叙利亚的反恐行动</td>\n",
       "      <td>俄罗斯在战争状态下的紧急动员能力，这不是土耳其可以低估的。</td>\n",
       "      <td>春节   放鞭炮   中央气象台   首次   发布   烟花爆竹   燃放   气象   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>深圳禁摩限电</td>\n",
       "      <td>珠海要是有这么高强度，市区就不会有那么多摩托车横冲直撞了</td>\n",
       "      <td>iPhoneSE   貌似   摄像头   外突   普天同庆</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>深圳禁摩限电</td>\n",
       "      <td>#深圳禁摩限电# 早该整了，快递开电车，真把马路当成他们家开的一样...不过他们工作压力大，...</td>\n",
       "      <td>千万   人口   级   城市   北京   原住民   庆祝   第一   节日   春...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>春节放鞭炮</td>\n",
       "      <td>发表了博文 《小年印象》 - 不知不觉，小年到了，俗称“祭灶”，即希望灶神“上天言好事，下地...</td>\n",
       "      <td>霉   奸   乌克兰   不会   战乱   中东   不会   大乱   伊死烂国   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>俄罗斯在叙利亚的反恐行动</td>\n",
       "      <td>这个土耳其一沾上他美爹的光就强硬起来了，不想想自己是个啥德行？自不量力！</td>\n",
       "      <td>皇恩浩荡   终于   开放   二胎   政策   记得   小时候   经常   看到 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>春节放鞭炮</td>\n",
       "      <td>今年上海过节放鞭炮的现象大为减少，空气质量也比较好，这次政府管制得很好，不断发劝告短消息给市...</td>\n",
       "      <td>苹果公司   宣布   美国   时间   月   日   发布   新   产品   包括...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>IphoneSE</td>\n",
       "      <td>喜欢小屏幕的苹果，现在还是4s，好吧，其实还有是因为穷</td>\n",
       "      <td>网上   曝光   图   看起来   不错   不太   喜欢   大屏   手机   兜</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>开放二胎</td>\n",
       "      <td>孕35+0，C一直都叫妹妹，妹妹的，周末婆婆估计终于憋不住了，对着C又像是自言自语的说道：你...</td>\n",
       "      <td>热点   快评   电动车   治理   系统工程   病根   国家   非机动车   标...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           target                                               text  \\\n",
       "0        IphoneSE                   讲真，对iphoneSE很心动，但是又很期待iphone7，心塞   \n",
       "1           春节放鞭炮                             传统春节来临传统的拜神，放鞭炮，烧纸，热闹呢   \n",
       "2    俄罗斯在叙利亚的反恐行动                      俄罗斯在战争状态下的紧急动员能力，这不是土耳其可以低估的。   \n",
       "3          深圳禁摩限电                       珠海要是有这么高强度，市区就不会有那么多摩托车横冲直撞了   \n",
       "4          深圳禁摩限电  #深圳禁摩限电# 早该整了，快递开电车，真把马路当成他们家开的一样...不过他们工作压力大，...   \n",
       "..            ...                                                ...   \n",
       "595         春节放鞭炮  发表了博文 《小年印象》 - 不知不觉，小年到了，俗称“祭灶”，即希望灶神“上天言好事，下地...   \n",
       "596  俄罗斯在叙利亚的反恐行动               这个土耳其一沾上他美爹的光就强硬起来了，不想想自己是个啥德行？自不量力！   \n",
       "597         春节放鞭炮  今年上海过节放鞭炮的现象大为减少，空气质量也比较好，这次政府管制得很好，不断发劝告短消息给市...   \n",
       "598      IphoneSE                        喜欢小屏幕的苹果，现在还是4s，好吧，其实还有是因为穷   \n",
       "599          开放二胎  孕35+0，C一直都叫妹妹，妹妹的，周末婆婆估计终于憋不住了，对着C又像是自言自语的说道：你...   \n",
       "\n",
       "                                                   cut  \n",
       "0    刚   回家   几天   迫不及待   赶到   小舅   家   看着   乖巧   懂...  \n",
       "1                                            俄罗斯   流氓   \n",
       "2    春节   放鞭炮   中央气象台   首次   发布   烟花爆竹   燃放   气象   ...  \n",
       "3                     iPhoneSE   貌似   摄像头   外突   普天同庆   \n",
       "4    千万   人口   级   城市   北京   原住民   庆祝   第一   节日   春...  \n",
       "..                                                 ...  \n",
       "595  霉   奸   乌克兰   不会   战乱   中东   不会   大乱   伊死烂国   ...  \n",
       "596  皇恩浩荡   终于   开放   二胎   政策   记得   小时候   经常   看到 ...  \n",
       "597  苹果公司   宣布   美国   时间   月   日   发布   新   产品   包括...  \n",
       "598    网上   曝光   图   看起来   不错   不太   喜欢   大屏   手机   兜   \n",
       "599  热点   快评   电动车   治理   系统工程   病根   国家   非机动车   标...  \n",
       "\n",
       "[600 rows x 3 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"dataset/testing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [i.split(\" \") for i in training]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.91149235\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "import multiprocessing\n",
    " \n",
    "def train_wordVectors(sentences, embedding_size = 50, window = 5, min_count = 1):\n",
    "    '''\n",
    "    :param sentences: sentences可以是LineSentence或者PathLineSentences读取的文件对象，也可以是\n",
    "                    The `sentences` iterable can be simply a list of lists of tokens,如lists=[['我','是','中国','人'],['我','的','家乡','在','广东']]\n",
    "    :param embedding_size: 词嵌入大小\n",
    "    :param window: 窗口\n",
    "    :param min_count:Ignores all words with total frequency lower than this.\n",
    "    :return: w2vModel\n",
    "    '''\n",
    "    w2vModel = word2vec.Word2Vec(sentences, size=embedding_size, window=window, min_count=min_count,workers=multiprocessing.cpu_count())\n",
    "    return w2vModel\n",
    " \n",
    "def save_wordVectors(w2vModel,word2vec_path):\n",
    "    w2vModel.save(word2vec_path)\n",
    " \n",
    "def load_wordVectors(word2vec_path):\n",
    "    w2vModel = word2vec.Word2Vec.load(word2vec_path)\n",
    "    return w2vModel\n",
    " \n",
    "if __name__=='__main__':\n",
    " \n",
    "    word2vec_path='word2Vec.model'\n",
    "    model2=train_wordVectors(a, embedding_size=50, window=5, min_count=1)\n",
    "    save_wordVectors(model2,word2vec_path)\n",
    "    model2=load_wordVectors(word2vec_path)\n",
    "    print(model2.wv.similarity(\"深圳\",\"俄罗斯\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format(r\"word embedding/cn.skipgram.bin\",binary=True,unicode_errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1635503"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(\"深圳\",\"俄罗斯\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  \n",
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.583189</td>\n",
       "      <td>2.130372</td>\n",
       "      <td>-26.202713</td>\n",
       "      <td>-8.923727</td>\n",
       "      <td>6.484468</td>\n",
       "      <td>18.861293</td>\n",
       "      <td>12.946058</td>\n",
       "      <td>-2.785165</td>\n",
       "      <td>-5.749008</td>\n",
       "      <td>-3.827543</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.009636</td>\n",
       "      <td>0.645828</td>\n",
       "      <td>-14.657746</td>\n",
       "      <td>-10.470855</td>\n",
       "      <td>-21.277053</td>\n",
       "      <td>-1.430176</td>\n",
       "      <td>9.096585</td>\n",
       "      <td>5.078261</td>\n",
       "      <td>-3.410602</td>\n",
       "      <td>-11.019945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.195311</td>\n",
       "      <td>0.079864</td>\n",
       "      <td>-1.025793</td>\n",
       "      <td>-0.339263</td>\n",
       "      <td>0.254341</td>\n",
       "      <td>0.751464</td>\n",
       "      <td>0.514491</td>\n",
       "      <td>-0.109752</td>\n",
       "      <td>-0.205636</td>\n",
       "      <td>-0.153152</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.500704</td>\n",
       "      <td>0.045291</td>\n",
       "      <td>-0.592562</td>\n",
       "      <td>-0.421232</td>\n",
       "      <td>-0.867570</td>\n",
       "      <td>-0.049362</td>\n",
       "      <td>0.374922</td>\n",
       "      <td>0.193969</td>\n",
       "      <td>-0.146967</td>\n",
       "      <td>-0.438258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.596611</td>\n",
       "      <td>2.724850</td>\n",
       "      <td>-33.270599</td>\n",
       "      <td>-11.268319</td>\n",
       "      <td>8.623322</td>\n",
       "      <td>24.379468</td>\n",
       "      <td>16.169671</td>\n",
       "      <td>-3.566423</td>\n",
       "      <td>-7.891737</td>\n",
       "      <td>-4.962621</td>\n",
       "      <td>...</td>\n",
       "      <td>-16.314008</td>\n",
       "      <td>1.214932</td>\n",
       "      <td>-18.347073</td>\n",
       "      <td>-13.366442</td>\n",
       "      <td>-27.243764</td>\n",
       "      <td>-1.308892</td>\n",
       "      <td>11.154958</td>\n",
       "      <td>6.673887</td>\n",
       "      <td>-4.547123</td>\n",
       "      <td>-13.739221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.567001</td>\n",
       "      <td>0.222205</td>\n",
       "      <td>-3.164547</td>\n",
       "      <td>-1.068910</td>\n",
       "      <td>0.813371</td>\n",
       "      <td>2.286470</td>\n",
       "      <td>1.559399</td>\n",
       "      <td>-0.290324</td>\n",
       "      <td>-0.677558</td>\n",
       "      <td>-0.488348</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.603483</td>\n",
       "      <td>0.132228</td>\n",
       "      <td>-1.799794</td>\n",
       "      <td>-1.308537</td>\n",
       "      <td>-2.643936</td>\n",
       "      <td>-0.166808</td>\n",
       "      <td>1.067169</td>\n",
       "      <td>0.569538</td>\n",
       "      <td>-0.409830</td>\n",
       "      <td>-1.292601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.491954</td>\n",
       "      <td>2.807478</td>\n",
       "      <td>-30.797740</td>\n",
       "      <td>-10.547736</td>\n",
       "      <td>7.676270</td>\n",
       "      <td>22.303603</td>\n",
       "      <td>15.319292</td>\n",
       "      <td>-3.538073</td>\n",
       "      <td>-6.826188</td>\n",
       "      <td>-4.595487</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.368514</td>\n",
       "      <td>0.737322</td>\n",
       "      <td>-17.203267</td>\n",
       "      <td>-12.231512</td>\n",
       "      <td>-25.049349</td>\n",
       "      <td>-1.436152</td>\n",
       "      <td>10.615528</td>\n",
       "      <td>5.948612</td>\n",
       "      <td>-3.978248</td>\n",
       "      <td>-13.063545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1          2          3         4          5          6   \\\n",
       "0  4.583189  2.130372 -26.202713  -8.923727  6.484468  18.861293  12.946058   \n",
       "1  0.195311  0.079864  -1.025793  -0.339263  0.254341   0.751464   0.514491   \n",
       "2  5.596611  2.724850 -33.270599 -11.268319  8.623322  24.379468  16.169671   \n",
       "3  0.567001  0.222205  -3.164547  -1.068910  0.813371   2.286470   1.559399   \n",
       "4  5.491954  2.807478 -30.797740 -10.547736  7.676270  22.303603  15.319292   \n",
       "\n",
       "         7         8         9   ...         40        41         42  \\\n",
       "0 -2.785165 -5.749008 -3.827543  ... -13.009636  0.645828 -14.657746   \n",
       "1 -0.109752 -0.205636 -0.153152  ...  -0.500704  0.045291  -0.592562   \n",
       "2 -3.566423 -7.891737 -4.962621  ... -16.314008  1.214932 -18.347073   \n",
       "3 -0.290324 -0.677558 -0.488348  ...  -1.603483  0.132228  -1.799794   \n",
       "4 -3.538073 -6.826188 -4.595487  ... -15.368514  0.737322 -17.203267   \n",
       "\n",
       "          43         44        45         46        47        48         49  \n",
       "0 -10.470855 -21.277053 -1.430176   9.096585  5.078261 -3.410602 -11.019945  \n",
       "1  -0.421232  -0.867570 -0.049362   0.374922  0.193969 -0.146967  -0.438258  \n",
       "2 -13.366442 -27.243764 -1.308892  11.154958  6.673887 -4.547123 -13.739221  \n",
       "3  -1.308537  -2.643936 -0.166808   1.067169  0.569538 -0.409830  -1.292601  \n",
       "4 -12.231512 -25.049349 -1.436152  10.615528  5.948612 -3.978248 -13.063545  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_review_vector(review):\n",
    "    \n",
    "\n",
    "    #words = nltk.word_tokenize(review)\n",
    "    word_vec = np.zeros((1,50))\n",
    "    for word in review:\n",
    "        #word_vec = np.zeros((1,300))\n",
    "        if word in model2:\n",
    "            word_vec += np.array([model2[word]])\n",
    "    #print (word_vec.mean(axis = 0))\n",
    "    return pd.Series(word_vec.mean(axis = 0))\n",
    "\n",
    "train_data_features_0 = train[\"cut\"].apply(to_review_vector)\n",
    "train_data_features_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['FAVOR', 'AGAINST', 'NONE'], dtype=object)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"stance\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"stance\"]=train[\"stance\"].map({\"FAVOR\":0,\"AGAINST\":1,\"NONE\":2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(\"stance\",axis=1)\n",
    "Y = train[\"stance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(train_data_features_0,Y,test_size=0.1,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2160, 50)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2160,)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LR_model = LogisticRegression()\n",
    "LR_model = LR_model.fit(x_train, y_train)\n",
    "y_pred = LR_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5125"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_pred == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43333333333333335"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "my_model = XGBClassifier()\n",
    "# Add silent=True to avoid printing out updates with each cycle\n",
    "my_model.fit(x_train, y_train)\n",
    "predictions = my_model.predict(x_test)\n",
    "\n",
    "np.mean(predictions == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OneVsRestClassifier(GradientBoostingClassifier(learning_rate=0.1,n_estimators=1000,max_depth=7))\n",
    "clt = model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4708333333333333"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clt.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
