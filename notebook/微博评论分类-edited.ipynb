{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "import jieba\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression,LogisticRegressionCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>开放二胎</td>\n",
       "      <td>刚回家几天就迫不及待的赶到了小舅家，看着乖巧懂事的表妹和可爱的小表弟，心情格外舒畅！这个画面...</td>\n",
       "      <td>FAVOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>俄罗斯在叙利亚的反恐行动</td>\n",
       "      <td>俄罗斯就是流氓</td>\n",
       "      <td>AGAINST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>春节放鞭炮</td>\n",
       "      <td>#春节放鞭炮#【中央气象台首次发布烟花爆竹燃放气象指数】明天就是除夕了，年味越发浓郁。今早，...</td>\n",
       "      <td>AGAINST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IphoneSE</td>\n",
       "      <td>iPhoneSE貌似摄像头不外突了，普天同庆</td>\n",
       "      <td>FAVOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>春节放鞭炮</td>\n",
       "      <td>千万人口级城市北京，原住民在庆祝第一大节日春节，大家伙都心照不宣的想到：别再给伤痕累累的家乡...</td>\n",
       "      <td>AGAINST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         target                                               text   stance\n",
       "0          开放二胎  刚回家几天就迫不及待的赶到了小舅家，看着乖巧懂事的表妹和可爱的小表弟，心情格外舒畅！这个画面...    FAVOR\n",
       "1  俄罗斯在叙利亚的反恐行动                                            俄罗斯就是流氓  AGAINST\n",
       "2         春节放鞭炮  #春节放鞭炮#【中央气象台首次发布烟花爆竹燃放气象指数】明天就是除夕了，年味越发浓郁。今早，...  AGAINST\n",
       "3      IphoneSE                             iPhoneSE貌似摄像头不外突了，普天同庆    FAVOR\n",
       "4         春节放鞭炮  千万人口级城市北京，原住民在庆祝第一大节日春节，大家伙都心照不宣的想到：别再给伤痕累累的家乡...  AGAINST"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"train.csv\",encoding=\"utf-8\",sep=\",\",delimiter=\"\\t\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwordslist():\n",
    "    stopwords = [line.strip() for line in open('cn_stopwords.txt',encoding='UTF-8').readlines()]\n",
    "    stopwords.extend([line.strip() for line in open('scu_stopwords.txt',encoding='UTF-8').readlines()])\n",
    "    stopwords.extend([line.strip() for line in open('baidu_stopwords.txt',encoding='UTF-8').readlines()])\n",
    "    stopwords.extend([line.strip() for line in open('hit_stopwords.txt',encoding='UTF-8').readlines()])\n",
    "    return stopwords\n",
    "        \n",
    "def seg_depart(sentence):\n",
    "     # 对文档中的每一行进行中文分词\n",
    "    sentence_depart = jieba.cut(sentence.strip())\n",
    "     # 创建一个停用词列表\n",
    "    stopwords = stopwordslist()\n",
    "    # 输出结果为outstr\n",
    "    outstr = ''\n",
    "   # 去停用词\n",
    "    for word in sentence_depart:\n",
    "        if word not in stopwords:\n",
    "            if word != '\\t':\n",
    "                outstr += word\n",
    "                outstr += \" \"\n",
    "    return outstr        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['开放二胎', '俄罗斯在叙利亚的反恐行动', '春节放鞭炮', 'IphoneSE', '深圳禁摩限电'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"target\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"target\"] = dataset[\"target\"].map({'开放二胎':0,'俄罗斯在叙利亚的反恐行动':1,'春节放鞭炮':2,'IphoneSE':3, '深圳禁摩限电':4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"stance\"] = dataset[\"stance\"].map({\"FAVOR\":0,\"AGAINST\":1,\"NONE\":2})\n",
    "dataset[\"cut\"] = dataset[\"text\"].apply(seg_depart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IphoneSE</td>\n",
       "      <td>讲真，对iphoneSE很心动，但是又很期待iphone7，心塞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>春节放鞭炮</td>\n",
       "      <td>传统春节来临传统的拜神，放鞭炮，烧纸，热闹呢</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>俄罗斯在叙利亚的反恐行动</td>\n",
       "      <td>俄罗斯在战争状态下的紧急动员能力，这不是土耳其可以低估的。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>深圳禁摩限电</td>\n",
       "      <td>珠海要是有这么高强度，市区就不会有那么多摩托车横冲直撞了</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>深圳禁摩限电</td>\n",
       "      <td>#深圳禁摩限电# 早该整了，快递开电车，真把马路当成他们家开的一样...不过他们工作压力大，...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         target                                               text\n",
       "0      IphoneSE                   讲真，对iphoneSE很心动，但是又很期待iphone7，心塞\n",
       "1         春节放鞭炮                             传统春节来临传统的拜神，放鞭炮，烧纸，热闹呢\n",
       "2  俄罗斯在叙利亚的反恐行动                      俄罗斯在战争状态下的紧急动员能力，这不是土耳其可以低估的。\n",
       "3        深圳禁摩限电                       珠海要是有这么高强度，市区就不会有那么多摩托车横冲直撞了\n",
       "4        深圳禁摩限电  #深圳禁摩限电# 早该整了，快递开电车，真把马路当成他们家开的一样...不过他们工作压力大，..."
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset = pd.read_csv(\"test.csv\",delimiter=\"\\t\")\n",
    "testset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset[\"target\"] = testset[\"target\"].map({'开放二胎':0,'俄罗斯在叙利亚的反恐行动':1,'春节放鞭炮':2,'IphoneSE':3, '深圳禁摩限电':4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset[\"cut\"] = testset[\"text\"].apply(seg_depart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0 = dataset[dataset[\"target\"]==0]\n",
    "x_1 = dataset[dataset[\"target\"]==1]\n",
    "x_2 = dataset[dataset[\"target\"]==2]\n",
    "x_3 = dataset[dataset[\"target\"]==3]\n",
    "x_4 = dataset[dataset[\"target\"]==4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>stance</th>\n",
       "      <th>cut</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>刚回家几天就迫不及待的赶到了小舅家，看着乖巧懂事的表妹和可爱的小表弟，心情格外舒畅！这个画面...</td>\n",
       "      <td>0</td>\n",
       "      <td>刚 回家 几天 迫不及待 赶到 小舅 家 看着 乖巧 懂事 表妹 可爱 小表弟 心情 舒畅 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>#姚晨怀二胎#恭喜，挑对了时间，又省了罚款。</td>\n",
       "      <td>0</td>\n",
       "      <td>姚晨怀 二胎 恭喜 挑对 时间 省 罚款</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>全面开放二胎政策总让人觉得“得不偿失”。优秀的因为这个政策被挤压了发展空间于是愤而起义坚决不...</td>\n",
       "      <td>1</td>\n",
       "      <td>开放 二胎 政策 总让 得不偿失 优秀 政策 挤压 发展 空间 愤而 起义 不生 不养 少生...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>不等到歌会结束啦~俺去补作业了，还是感谢奇然让我一本满足呐！最后的最后的最后，祝二胎茁壮成长...</td>\n",
       "      <td>2</td>\n",
       "      <td>歌会 结束 ~ 补 作业 感谢 奇然 一本 呐 祝 二胎 茁壮成长 ฅ ω ฅ 嘿嘿嘿 ~ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>国际知名咨询公司凯度发布研究称，此前，婴儿奶粉业内预估，受二胎政策推动，2015年~2018...</td>\n",
       "      <td>2</td>\n",
       "      <td>国际 知名 咨询 公司 凯度 发布 研究 称 此前 婴儿 奶粉 业内 预估 受 二胎 政策 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2378</th>\n",
       "      <td>0</td>\n",
       "      <td>很多人都在释放什么北上广的房子合起来可以把美国买下之类的危机大预言术，用以佐证中国房价高。那...</td>\n",
       "      <td>0</td>\n",
       "      <td>释放 北上 广 房子 合 美国 买下 危机 预言 术 用以 佐证 中国 房价 高 中国 人口...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2383</th>\n",
       "      <td>0</td>\n",
       "      <td>发表了博文《试管婴儿二胎》您是否也在纠结要二胎？担心二胎成功率，费用？柒月健康小奎详细的开一...</td>\n",
       "      <td>0</td>\n",
       "      <td>发表 博文 试管婴儿 二胎 纠结 二胎 担心 二胎 成功率 费用 柒月 健康 小奎 详细 开...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2384</th>\n",
       "      <td>0</td>\n",
       "      <td>连续三天奔松江，在成就感满满的今天画上句号。七点出发去给本科小朋友上形势政策课，4个小时，讲...</td>\n",
       "      <td>0</td>\n",
       "      <td>连续 三天 奔 松江 成就感 满满的 画上 句号 七点 出发 本科 小朋友 形势 政策 课 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2387</th>\n",
       "      <td>0</td>\n",
       "      <td>口味独特不反对！男的都跟男的搞女的都跟女的搞了！怪不得开放二胎</td>\n",
       "      <td>0</td>\n",
       "      <td>口味 独特 反对 男 男 搞 女 女 搞 开放 二胎</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390</th>\n",
       "      <td>0</td>\n",
       "      <td>光开放二胎有屁用啊，还不是女人辛苦？又要生、又要带、又要赚钱，请求开放二夫！！</td>\n",
       "      <td>1</td>\n",
       "      <td>光 开放 二胎 屁用 女人 辛苦 要生 带 赚钱 请求 开放 二夫</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>493 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      target                                               text  stance  \\\n",
       "0          0  刚回家几天就迫不及待的赶到了小舅家，看着乖巧懂事的表妹和可爱的小表弟，心情格外舒畅！这个画面...       0   \n",
       "9          0                             #姚晨怀二胎#恭喜，挑对了时间，又省了罚款。       0   \n",
       "15         0  全面开放二胎政策总让人觉得“得不偿失”。优秀的因为这个政策被挤压了发展空间于是愤而起义坚决不...       1   \n",
       "17         0  不等到歌会结束啦~俺去补作业了，还是感谢奇然让我一本满足呐！最后的最后的最后，祝二胎茁壮成长...       2   \n",
       "19         0  国际知名咨询公司凯度发布研究称，此前，婴儿奶粉业内预估，受二胎政策推动，2015年~2018...       2   \n",
       "...      ...                                                ...     ...   \n",
       "2378       0  很多人都在释放什么北上广的房子合起来可以把美国买下之类的危机大预言术，用以佐证中国房价高。那...       0   \n",
       "2383       0  发表了博文《试管婴儿二胎》您是否也在纠结要二胎？担心二胎成功率，费用？柒月健康小奎详细的开一...       0   \n",
       "2384       0  连续三天奔松江，在成就感满满的今天画上句号。七点出发去给本科小朋友上形势政策课，4个小时，讲...       0   \n",
       "2387       0                    口味独特不反对！男的都跟男的搞女的都跟女的搞了！怪不得开放二胎       0   \n",
       "2390       0            光开放二胎有屁用啊，还不是女人辛苦？又要生、又要带、又要赚钱，请求开放二夫！！       1   \n",
       "\n",
       "                                                    cut  \n",
       "0     刚 回家 几天 迫不及待 赶到 小舅 家 看着 乖巧 懂事 表妹 可爱 小表弟 心情 舒畅 ...  \n",
       "9                                 姚晨怀 二胎 恭喜 挑对 时间 省 罚款   \n",
       "15    开放 二胎 政策 总让 得不偿失 优秀 政策 挤压 发展 空间 愤而 起义 不生 不养 少生...  \n",
       "17    歌会 结束 ~ 补 作业 感谢 奇然 一本 呐 祝 二胎 茁壮成长 ฅ ω ฅ 嘿嘿嘿 ~ ...  \n",
       "19    国际 知名 咨询 公司 凯度 发布 研究 称 此前 婴儿 奶粉 业内 预估 受 二胎 政策 ...  \n",
       "...                                                 ...  \n",
       "2378  释放 北上 广 房子 合 美国 买下 危机 预言 术 用以 佐证 中国 房价 高 中国 人口...  \n",
       "2383  发表 博文 试管婴儿 二胎 纠结 二胎 担心 二胎 成功率 费用 柒月 健康 小奎 详细 开...  \n",
       "2384  连续 三天 奔 松江 成就感 满满的 画上 句号 七点 出发 本科 小朋友 形势 政策 课 ...  \n",
       "2387                        口味 独特 反对 男 男 搞 女 女 搞 开放 二胎   \n",
       "2390                 光 开放 二胎 屁用 女人 辛苦 要生 带 赚钱 请求 开放 二夫   \n",
       "\n",
       "[493 rows x 4 columns]"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_0 = testset[testset[\"target\"]==0]\n",
    "y_1 = testset[testset[\"target\"]==1]\n",
    "y_2 = testset[testset[\"target\"]==2]\n",
    "y_3 = testset[testset[\"target\"]==3]\n",
    "y_4 = testset[testset[\"target\"]==4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>cut</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>#和颐酒店女生遇袭# 我真的对TC有点失望了，开放二胎号召女性回归家庭，这些都是潜意识的洗脑...</td>\n",
       "      <td>颐 酒店 女生 遇袭   真的 TC 失望 开放 二胎 号召 女性 回归 家庭 潜意识 洗脑...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>【北京交通委：油价大跌和网络约车加剧道路拥堵】北京市交通委主任周正宇今天说，八项规定出台后，...</td>\n",
       "      <td>北京 交通委 油价 大跌 网络 约车 加剧 道路 拥堵 北京市 交通委 主任 周正 宇 说 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>【女孩遭遇准婆婆奇葩要求 考上研究生才能结婚】准婆婆要求一对90后小情侣写下保证书，保证二人...</td>\n",
       "      <td>女孩 遭遇 准 婆婆 奇葩   考上 研究生 结婚 准 婆婆 一对 90 情侣 写下 保证书...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>虽然开放二胎我觉得是个好事，但是能别再特么煽情说独生子女孤独了吗？老子一点也不孤独啊，就特么...</td>\n",
       "      <td>开放 二胎 好事 能别 特 煽情 说 独生子女 孤独 老子 一点 孤独 特 代表</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "      <td>4月24日，姚晨在电影《梦想合伙人》首映礼上，宣布怀二胎，十一月将生下二宝，给小土豆添一个小...</td>\n",
       "      <td>月 24 日 姚晨 电影 梦想 合伙人 首映礼 怀 二胎 十一月 将生 下二宝 小土豆 添 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>0</td>\n",
       "      <td>【每日话题】随着“二胎政策”开放，生宝宝扎堆。为避免员工集中怀孕，吉林长春一单位定新规：想要...</td>\n",
       "      <td>每日 话题 二胎 政策 开放 生 宝宝 扎堆 员工 怀孕 吉林长春 单位 定新规 想要 孩子...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>0</td>\n",
       "      <td>办公室瑕姐刚生完小布丁，最近办公室天天聊育儿话题。没想到今天早上老大来超平静的宣布她怀上二胎...</td>\n",
       "      <td>办公室 瑕姐 刚生 完小 布丁 办公室 天天 聊 育儿 话题 没想到 早上 老大 来超 平静...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>0</td>\n",
       "      <td>#90后断崖式减少#【震惊！中国90后数量现“断崖式减少”，已经成珍惜物种?】“少壮不养孩，...</td>\n",
       "      <td>90 断崖 式 减少 震惊 中国 90 数量 现 断崖 式 减少 成 珍惜 物种 少壮 不养...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>0</td>\n",
       "      <td>开放二胎后舆论导向越来越没谱了。刚中央七居然在播江西的添丁仪式，杀公鸡，祈求添丁。周围抱着的...</td>\n",
       "      <td>开放 二胎 舆论导向 越来越 没谱 刚 中央 七 在播 江西 添丁 仪式 杀 公鸡 祈求 添...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>0</td>\n",
       "      <td>孕35+0，C一直都叫妹妹，妹妹的，周末婆婆估计终于憋不住了，对着C又像是自言自语的说道：你...</td>\n",
       "      <td>孕 35 C 妹妹 妹妹 周末 婆婆 估计 终于 憋不住 C 像是 自言自语 说道 妹妹 怪...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     target                                               text  \\\n",
       "5         0  #和颐酒店女生遇袭# 我真的对TC有点失望了，开放二胎号召女性回归家庭，这些都是潜意识的洗脑...   \n",
       "6         0  【北京交通委：油价大跌和网络约车加剧道路拥堵】北京市交通委主任周正宇今天说，八项规定出台后，...   \n",
       "15        0  【女孩遭遇准婆婆奇葩要求 考上研究生才能结婚】准婆婆要求一对90后小情侣写下保证书，保证二人...   \n",
       "32        0  虽然开放二胎我觉得是个好事，但是能别再特么煽情说独生子女孤独了吗？老子一点也不孤独啊，就特么...   \n",
       "38        0  4月24日，姚晨在电影《梦想合伙人》首映礼上，宣布怀二胎，十一月将生下二宝，给小土豆添一个小...   \n",
       "..      ...                                                ...   \n",
       "571       0  【每日话题】随着“二胎政策”开放，生宝宝扎堆。为避免员工集中怀孕，吉林长春一单位定新规：想要...   \n",
       "581       0  办公室瑕姐刚生完小布丁，最近办公室天天聊育儿话题。没想到今天早上老大来超平静的宣布她怀上二胎...   \n",
       "583       0  #90后断崖式减少#【震惊！中国90后数量现“断崖式减少”，已经成珍惜物种?】“少壮不养孩，...   \n",
       "587       0  开放二胎后舆论导向越来越没谱了。刚中央七居然在播江西的添丁仪式，杀公鸡，祈求添丁。周围抱着的...   \n",
       "599       0  孕35+0，C一直都叫妹妹，妹妹的，周末婆婆估计终于憋不住了，对着C又像是自言自语的说道：你...   \n",
       "\n",
       "                                                   cut  \n",
       "5    颐 酒店 女生 遇袭   真的 TC 失望 开放 二胎 号召 女性 回归 家庭 潜意识 洗脑...  \n",
       "6    北京 交通委 油价 大跌 网络 约车 加剧 道路 拥堵 北京市 交通委 主任 周正 宇 说 ...  \n",
       "15   女孩 遭遇 准 婆婆 奇葩   考上 研究生 结婚 准 婆婆 一对 90 情侣 写下 保证书...  \n",
       "32           开放 二胎 好事 能别 特 煽情 说 独生子女 孤独 老子 一点 孤独 特 代表   \n",
       "38   月 24 日 姚晨 电影 梦想 合伙人 首映礼 怀 二胎 十一月 将生 下二宝 小土豆 添 ...  \n",
       "..                                                 ...  \n",
       "571  每日 话题 二胎 政策 开放 生 宝宝 扎堆 员工 怀孕 吉林长春 单位 定新规 想要 孩子...  \n",
       "581  办公室 瑕姐 刚生 完小 布丁 办公室 天天 聊 育儿 话题 没想到 早上 老大 来超 平静...  \n",
       "583  90 断崖 式 减少 震惊 中国 90 数量 现 断崖 式 减少 成 珍惜 物种 少壮 不养...  \n",
       "587  开放 二胎 舆论导向 越来越 没谱 刚 中央 七 在播 江西 添丁 仪式 杀 公鸡 祈求 添...  \n",
       "599  孕 35 C 妹妹 妹妹 周末 婆婆 估计 终于 憋不住 C 像是 自言自语 说道 妹妹 怪...  \n",
       "\n",
       "[107 rows x 3 columns]"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 开放二胎 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_0 = x_0.drop(\"stance\",axis=1)\n",
    "Y_0 = x_0[\"stance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf(contents):\n",
    "    # 提取文本特征tf-idf\n",
    "    vectorizer = CountVectorizer(min_df=1e-5,max_features=1400)\n",
    "    transformer = TfidfTransformer()\n",
    "    tfidf = transformer.fit_transform(vectorizer.fit_transform(contents))\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<493x1400 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 6248 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf(X_0[\"cut\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(tf_idf(X_0[\"cut\"]),Y_0,random_state=1,test_size =0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(394, 1400)"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "贝叶斯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alph is 0.0,score is 0.5656565656565656\n",
      "alph is 0.1,score is 0.5454545454545454\n",
      "alph is 0.2,score is 0.5858585858585859\n",
      "alph is 0.30000000000000004,score is 0.5959595959595959\n",
      "alph is 0.4,score is 0.5858585858585859\n",
      "alph is 0.5,score is 0.5858585858585859\n",
      "alph is 0.6000000000000001,score is 0.5858585858585859\n",
      "alph is 0.7000000000000001,score is 0.5858585858585859\n",
      "alph is 0.8,score is 0.6161616161616161\n",
      "alph is 0.9,score is 0.6161616161616161\n",
      "alph is 1.0,score is 0.6161616161616161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB(0,fit_prior=False)\n",
    "for i in np.arange(0.0,1.1,0.1):\n",
    "    classifier = MultinomialNB(i,fit_prior=True)\n",
    "#模型训练\n",
    "    classifier.fit(x_train, y_train)\n",
    "    scores = classifier.score(x_test, y_test)\n",
    "    print(\"alph is {0},score is {1}\".format(i,scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbours is 1, score is 0.494949494949495\n",
      "n_neighbours is 2, score is 0.5454545454545454\n",
      "n_neighbours is 3, score is 0.5050505050505051\n",
      "n_neighbours is 4, score is 0.5252525252525253\n",
      "n_neighbours is 5, score is 0.5555555555555556\n",
      "n_neighbours is 6, score is 0.5050505050505051\n",
      "n_neighbours is 7, score is 0.5050505050505051\n",
      "n_neighbours is 8, score is 0.5252525252525253\n",
      "n_neighbours is 9, score is 0.5151515151515151\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "for i in range(1,10):\n",
    "    knc = KNeighborsClassifier(n_neighbors=i)\n",
    "    knc.fit(x_train, y_train)\n",
    "    y_predict = knc.predict(x_test)\n",
    "    score = np.mean(y_predict == y_test)\n",
    "    print(\"n_neighbours is {0}, score is {1}\".format(i,score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5656565656565656"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_model = SVC(kernel=\"linear\")\n",
    "svm_model.fit(x_train, y_train)\n",
    "\n",
    "preds = svm_model .predict(x_test)\n",
    "np.mean( preds == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error : 0.6136006258352839\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "my_model = XGBRegressor()\n",
    "# Add silent=True to avoid printing out updates with each cycle\n",
    "my_model.fit(x_train, y_train, verbose=False)\n",
    "predictions = my_model.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print(\"Mean Absolute Error : \" + str(mean_absolute_error(predictions, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "####读取测试集  预测\n",
    "classifier = MultinomialNB(1,fit_prior=False)\n",
    "classifier.fit(x_train, y_train)\n",
    "res = classifier.predict(tf_idf(y_0[\"cut\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "for count,index in enumerate(y_0[\"cut\"].index):\n",
    "    result[index] = res[count] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 俄罗斯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1 = x_1.drop(\"stance\",axis=1)\n",
    "Y_1 = x_1[\"stance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf(contents):\n",
    "    # 提取文本特征tf-idf\n",
    "    vectorizer = CountVectorizer(min_df=1e-5,max_features=910)\n",
    "    transformer = TfidfTransformer()\n",
    "    tfidf = transformer.fit_transform(vectorizer.fit_transform(contents))\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(tf_idf(X_1[\"cut\"]),Y_1,random_state=1,test_size =0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alph is 0.0,score is 0.47959183673469385\n",
      "alph is 0.1,score is 0.5204081632653061\n",
      "alph is 0.2,score is 0.5408163265306123\n",
      "alph is 0.30000000000000004,score is 0.5510204081632653\n",
      "alph is 0.4,score is 0.5510204081632653\n",
      "alph is 0.5,score is 0.5510204081632653\n",
      "alph is 0.6000000000000001,score is 0.5408163265306123\n",
      "alph is 0.7000000000000001,score is 0.5306122448979592\n",
      "alph is 0.8,score is 0.5306122448979592\n",
      "alph is 0.9,score is 0.5306122448979592\n",
      "alph is 1.0,score is 0.5204081632653061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    }
   ],
   "source": [
    "###贝叶斯\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB(0,fit_prior=False)\n",
    "for i in np.arange(0.0,1.1,0.1):\n",
    "    classifier = MultinomialNB(i,fit_prior=True)\n",
    "#模型训练\n",
    "    classifier.fit(x_train, y_train)\n",
    "    scores = classifier.score(x_test, y_test)\n",
    "    print(\"alph is {0},score is {1}\".format(i,scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbours is 1, score is 0.30612244897959184\n",
      "n_neighbours is 2, score is 0.3673469387755102\n",
      "n_neighbours is 3, score is 0.30612244897959184\n",
      "n_neighbours is 4, score is 0.3979591836734694\n",
      "n_neighbours is 5, score is 0.35714285714285715\n",
      "n_neighbours is 6, score is 0.37755102040816324\n",
      "n_neighbours is 7, score is 0.2857142857142857\n",
      "n_neighbours is 8, score is 0.47959183673469385\n",
      "n_neighbours is 9, score is 0.4387755102040816\n"
     ]
    }
   ],
   "source": [
    "##knn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "for i in range(1,10):\n",
    "    knc = KNeighborsClassifier(n_neighbors=i)\n",
    "    knc.fit(x_train, y_train)\n",
    "    y_predict = knc.predict(x_test)\n",
    "    score = np.mean(y_predict == y_test)\n",
    "    print(\"n_neighbours is {0}, score is {1}\".format(i,score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5612244897959183"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##逻辑回归\n",
    "lr_model = LogisticRegression( multi_class='multinomial', n_jobs=-1,random_state=1)\n",
    "lr_model.fit(x_train, y_train)\n",
    "\n",
    "preds = lr_model.predict(x_test)\n",
    "np.mean( preds == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5714285714285714"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##支持向量机\n",
    "from sklearn.svm import SVC\n",
    "svm_model = SVC(kernel=\"linear\")\n",
    "svm_model.fit(x_train, y_train)\n",
    "\n",
    "preds = svm_model .predict(x_test)\n",
    "np.mean( preds == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5510204081632653"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "lr_model = LogisticRegressionCV(solver='newton-cg', multi_class='multinomial', cv=5, n_jobs=-1)\n",
    "lr_model.fit(x_train, y_train)\n",
    "\n",
    "preds = lr_model.predict(x_test)\n",
    "np.mean( preds == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110, 910)"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf(y_1[\"cut\"]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = svm_model .predict(tf_idf(y_1[\"cut\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "for count,index in enumerate(y_1[\"cut\"].index):\n",
    "    result[index] = preds[count] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "for count,index in enumerate(y_1[\"cut\"].index):\n",
    "    result[index] = res[count] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "217"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(result))\n",
    "len(y_0)+len(y_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "217"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "###2\n",
    "\n",
    "X_2 = x_2.drop(\"stance\",axis=1)\n",
    "Y_2 = x_2[\"stance\"]\n",
    "\n",
    "def tf_idf(contents):\n",
    "    # 提取文本特征tf-idf\n",
    "    vectorizer = CountVectorizer(min_df=1e-5,max_features=1900)\n",
    "    transformer = TfidfTransformer()\n",
    "    tfidf = transformer.fit_transform(vectorizer.fit_transform(contents))\n",
    "    return tfidf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(tf_idf(X_2[\"cut\"]),Y_2,random_state=1,test_size =0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alph is 0.0,score is 0.6404494382022472\n",
      "alph is 0.1,score is 0.7303370786516854\n",
      "alph is 0.2,score is 0.7415730337078652\n",
      "alph is 0.30000000000000004,score is 0.7415730337078652\n",
      "alph is 0.4,score is 0.7415730337078652\n",
      "alph is 0.5,score is 0.7303370786516854\n",
      "alph is 0.6000000000000001,score is 0.7191011235955056\n",
      "alph is 0.7000000000000001,score is 0.7078651685393258\n",
      "alph is 0.8,score is 0.6966292134831461\n",
      "alph is 0.9,score is 0.6853932584269663\n",
      "alph is 1.0,score is 0.6853932584269663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    }
   ],
   "source": [
    "###贝叶斯\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB(0,fit_prior=False)\n",
    "for i in np.arange(0.0,1.1,0.1):\n",
    "    classifier = MultinomialNB(i,fit_prior=True)\n",
    "#模型训练\n",
    "    classifier.fit(x_train, y_train)\n",
    "    scores = classifier.score(x_test, y_test)\n",
    "    print(\"alph is {0},score is {1}\".format(i,scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbours is 1, score is 0.5955056179775281\n",
      "n_neighbours is 2, score is 0.5617977528089888\n",
      "n_neighbours is 3, score is 0.6179775280898876\n",
      "n_neighbours is 4, score is 0.5955056179775281\n",
      "n_neighbours is 5, score is 0.5955056179775281\n",
      "n_neighbours is 6, score is 0.6292134831460674\n",
      "n_neighbours is 7, score is 0.6853932584269663\n",
      "n_neighbours is 8, score is 0.6741573033707865\n",
      "n_neighbours is 9, score is 0.6741573033707865\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "for i in range(1,10):\n",
    "    knc = KNeighborsClassifier(n_neighbors=i)\n",
    "    knc.fit(x_train, y_train)\n",
    "    y_predict = knc.predict(x_test)\n",
    "    score = np.mean(y_predict == y_test)\n",
    "    print(\"n_neighbours is {0}, score is {1}\".format(i,score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7191011235955056"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##逻辑回归\n",
    "lr_model = LogisticRegression( multi_class='multinomial', n_jobs=-1,random_state=1)\n",
    "lr_model.fit(x_train, y_train)\n",
    "\n",
    "preds = lr_model.predict(x_test)\n",
    "np.mean( preds == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7415730337078652"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##支持向量机\n",
    "from sklearn.svm import SVC\n",
    "svm_model = SVC(kernel=\"linear\")\n",
    "svm_model.fit(x_train, y_train)\n",
    "\n",
    "preds = svm_model .predict(x_test)\n",
    "np.mean( preds == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7303370786516854"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "lr_model = LogisticRegressionCV(solver='newton-cg', multi_class='multinomial', cv=5, n_jobs=-1)\n",
    "lr_model.fit(x_train, y_train)\n",
    "\n",
    "preds = lr_model.predict(x_test)\n",
    "np.mean( preds == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(155, 1900)"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf(y_2[\"cut\"]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = svm_model .predict(tf_idf(y_2[\"cut\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "for count,index in enumerate(y_2[\"cut\"].index):\n",
    "    result[index] = preds[count] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "372\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "372"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(result))\n",
    "len(y_0)+len(y_1)+len(y_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 朴素贝叶斯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alph is 0.0,score is 0.55\n",
      "alph is 0.1,score is 0.5770833333333333\n",
      "alph is 0.2,score is 0.5833333333333334\n",
      "alph is 0.30000000000000004,score is 0.5833333333333334\n",
      "alph is 0.4,score is 0.5854166666666667\n",
      "alph is 0.5,score is 0.5875\n",
      "alph is 0.6000000000000001,score is 0.5895833333333333\n",
      "alph is 0.7000000000000001,score is 0.5854166666666667\n",
      "alph is 0.8,score is 0.58125\n",
      "alph is 0.9,score is 0.5854166666666667\n",
      "alph is 1.0,score is 0.5854166666666667\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0.0,1.1,0.1):\n",
    "    classifier = MultinomialNB(i,fit_prior=False)\n",
    "#模型训练\n",
    "    classifier.fit(vectorizer.transform(x_train[\"cut\"] ) + vectorizer.transform(fenci(x_train['target'])), y_train)\n",
    "    scores = classifier.score(vectorizer.transform(x_test[\"cut\"])+vectorizer.transform(fenci(x_test['target'])), y_test)\n",
    "    print(\"alph is {0},score is {1}\".format(i,scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alph is 0.0,score is 0.55\n",
      "alph is 0.1,score is 0.5833333333333334\n",
      "alph is 0.2,score is 0.5833333333333334\n",
      "alph is 0.30000000000000004,score is 0.5833333333333334\n",
      "alph is 0.4,score is 0.5833333333333334\n",
      "alph is 0.5,score is 0.5791666666666667\n",
      "alph is 0.6000000000000001,score is 0.5854166666666667\n",
      "alph is 0.7000000000000001,score is 0.5833333333333334\n",
      "alph is 0.8,score is 0.5875\n",
      "alph is 0.9,score is 0.58125\n",
      "alph is 1.0,score is 0.5791666666666667\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0.0,1.1,0.1):\n",
    "    classifier = MultinomialNB(i,fit_prior=True)\n",
    "#模型训练\n",
    "    classifier.fit(vectorizer.transform(x_train[\"cut\"] ) + vectorizer.transform(fenci(x_train['target'])), y_train)\n",
    "    scores = classifier.score(vectorizer.transform(x_test[\"cut\"])+vectorizer.transform(fenci(x_test['target'])), y_test)\n",
    "    print(\"alph is {0},score is {1}\".format(i,scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1, class_prior=None, fit_prior=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = MultinomialNB(1,fit_prior=False)\n",
    "#模型训练\n",
    "classifier.fit(vectorizer.transform(x_train[\"cut\"] ) + vectorizer.transform(fenci(x_train['target'])), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = classifier.predict(vectorizer.transform(x_test[\"cut\"] ) + vectorizer.transform(fenci(x_test['target'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test.csv\",delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['IphoneSE', '春节放鞭炮', '俄罗斯在叙利亚的反恐行动', '深圳禁摩限电', '开放二胎'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"target\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"cut\"] = test[\"text\"].apply(seg_depart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input  = vectorizer.transform(test[\"cut\"] ) + vectorizer.transform(fenci(test['target']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#['FAVOR', 'AGAINST', 'NONE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('key.csv', 'w', encoding='utf-8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='excel')\n",
    "    for index,res in enumerate(classifier.predict(test_input)):\n",
    "        fin = \"\"\n",
    "        if res == 0:\n",
    "            fin = \"FAVOR\"\n",
    "        if res == 1:\n",
    "            fin = 'AGAINST'\n",
    "        if res == 2:\n",
    "            fin = 'NONE'\n",
    "        writer.writerow([index,fin])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
